√≥
k2√ÆWc           @   s√¨   d  Z  d d l m Z d d l Z d d l Z d d l Z d d l Z d d l Z d d l Z d d l	 Z	 d d l
 Z
 d d l Z e ∆í  Z d e
 f d ‚Äû  ∆í  YZ d e
 f d ‚Äû  ∆í  YZ d e
 f d	 ‚Äû  ∆í  YZ d
 ‚Äû  Z d ‚Äû  Z d ‚Äû  Z d S(
   s¬Ø  
# ================================================================================#
#-- PROJECT NAME : Diarization package using i-vector clustering. 
#-- BACKEND : LIUM Speaker Diarization
#-- TASK : This module containing high level classes relatives to the speaker 
		   recognition task

#-- Author : Sruthi.S
#-- Date : September 27th, 2016
# ================================================================================#
i√ø√ø√ø√ø(   t   VConfNt   Segmentc           B   s‚Ä†   e  Z d  Z d ‚Äû  Z d ‚Äû  Z d ‚Äû  Z d ‚Äû  Z d ‚Äû  Z d ‚Äû  Z d ‚Äû  Z	 d ‚Äû  Z
 d	 ‚Äû  Z d
 ‚Äû  Z d ‚Äû  Z
 d ‚Äû  Z d d
 ‚Äû Z RS(   s¬¨   A Segment taken from a segmentation file, representing the smallest
    recognized voice time slice.

    :type line: string
    :param line: the line taken from a seg filec         C   s¬¶   t  | d ∆í |  _ t | d ∆í |  _ t | d ∆í |  _ t | d ∆í |  _ t  | d ∆í |  _ t  | d ∆í |  _ t  | d ∆í |  _ t  | d ∆í |  _	 | |  _
 d	 S(
   sO   
        :type line: string
        :param line: the line taken from a seg filei    i   i   i   i   i   i   i   N(   t   strt	   _basenamet   intt   _onet   _startt	   _durationt   _gendert   _environmentt   _uuut   _speakert   _line(   t   selft   line(    (    s   voiceid_ilp/sr.pyt   __init__!   s    c         C   s
   t  |  j ∆í S(   N(   R   R   (   R
   (    (    s   voiceid_ilp/sr.pyt   __repr__/   s    c         C   s6   |  j  | j ∆í  k  r d S|  j  | j ∆í  k r2 d Sd S(   Ni√ø√ø√ø√øi   i    (   R   t	   get_start(   R
   t   other(    (    s   voiceid_ilp/sr.pyt   __cmp__2   s
    c         C   sB   | j  ∆í  |  j  ∆í  |  _ |  j | j ∆í  7_ |  j |  j d <d S(   s√†   Merge two adjacent segments, the otr in to the original.
        Do not use for segments that are not adjacent, it can have
        odd behaviour.

        :type otr: Segment
        :param otr: the segment to be merged withi   N(   R   R   t   get_durationR   (   R
   t   otr(    (    s   voiceid_ilp/sr.pyt   merge9   s    c         C   s   | |  j  d <|  _ d S(   s¬è   Change the identifier of the segment.

        :type identifier: string
        :param identifier: the identifier of the speaker in the segmenti   N(   R   R   (   R
   t
   identifier(    (    s   voiceid_ilp/sr.pyt   renameD   s    c         C   s   |  j  S(   s?   Get the basename of the original file which belong the segment.(   R   (   R
   (    (    s   voiceid_ilp/sr.pyt   get_basenameK   s    c         C   s   |  j  S(   s)   Get the start frame index of the segment.(   R   (   R
   (    (    s   voiceid_ilp/sr.pyR   O   s    c         C   s   |  j  |  j S(   s'   Get the end frame index of the segment.(   R   R   (   R
   (    (    s   voiceid_ilp/sr.pyt   get_endS   s    c         C   s   |  j  S(   s*   Get the duration of the segment in frames.(   R   (   R
   (    (    s   voiceid_ilp/sr.pyR   W   s    c         C   s   |  j  S(   s   Get the gender of the segment.(   R   (   R
   (    (    s   voiceid_ilp/sr.pyt
   get_gender[   s    c         C   s   |  j  S(   s#   Get the environment of the segment.(   R	   (   R
   (    (    s   voiceid_ilp/sr.pyt   get_environment_   s    c         C   s   |  j  S(   s*   Get the speaker identifier of the segment.(   R   (   R
   (    (    s   voiceid_ilp/sr.pyt   get_speakerc   s    c         C   s   |  j  S(   s5   Get the line of the segment in the original seg file.(   R   (   R
   t   cluster(    (    s   voiceid_ilp/sr.pyt   get_lineg   s    N(   t   __name__t
   __module__t   __doc__R   R   R   R   R   R   R   R   R   R   R   R   t   NoneR   (    (    (    s   voiceid_ilp/sr.pyR      s   												t   Clusterc           B   s  e  Z d  Z d d ‚Äû Z d ‚Äû  Z d ‚Äû  Z d ‚Äû  Z d ‚Äû  Z d ‚Äû  Z	 d ‚Äû  Z
 d ‚Äû  Z d	 ‚Äû  Z d
 ‚Äû  Z
 d ‚Äû  Z d ‚Äû  Z d
 ‚Äû  Z d ‚Äû  Z d ‚Äû  Z d ‚Äû  Z d ‚Äû  Z d ‚Äû  Z d ‚Äû  Z d ‚Äû  Z d ‚Äû  Z d ‚Äû  Z d ‚Äû  Z d ‚Äû  Z d ‚Äû  Z d ‚Äû  Z e d ‚Äû Z d ‚Äû  Z  d ‚Äû  Z! RS(   s  A Cluster object, representing a computed cluster for a single
    speaker, with gender, a number of frames and environment.

    :type identifier: string
    :param identifier: the cluster identifier

    :type gender: char F, M or U
    :param gender: the gender of the cluster

    :type frames: integer
    :param frames: total frames of the cluster

    :type dirname: string
    :param dirname: the directory where is the cluster wave file
    
    :type label: string
    :param label: the cluster identifier
    c         C   s‚Äì   | |  _  | |  _ d |  _ | |  _ | |  _ g  |  _ d | |  _ |  j d 7_ |  j d 7_ i  |  _ t	 |  _
 | d |  _ | |  _ d |  _
 d S(   s`  
        :type identifier: string
        :param identifier: the cluster identifier

        :type gender: char F, M or U
        :param gender: the gender of the cluster

        :type frames: integer
        :param frames: total frames of the cluster

        :type dirname: string
        :param dirname: the directory where is the cluster wave files    ;; cluster:%s [ score:FS = 0.0 ]s&    [ score:FT = 0.0 ] [ score:MS = 0.0 ]s    [ score:MT = 0.0 ]
s   .wavN(   t   gendert   _framesR#   t   _envt   _labelR   t	   _segmentst   _seg_headert   speakerst   Truet
   up_to_datet   wavet   dirnamet   value(   R
   R   R%   t   framesR/   t   label(    (    s   voiceid_ilp/sr.pyR   ‚Ç¨   s    						
		
	c         C   s   d |  j  |  j f S(   Ns   %s (%s)(   R(   R   (   R
   (    (    s   voiceid_ilp/sr.pyt   __str__≈∏   s    c         C   s   |  j  j | ∆í d  S(   N(   R)   t   append(   R
   t   segment(    (    s   voiceid_ilp/sr.pyt   add_segment¬¢   s    c         C   sM   |  j  s t d ∆í ‚Äö n  d |  j  |  _ |  j d 7_ |  j d 7_ |  j S(   Ns    no label defined for the Clusters    ;; cluster:%s [ score:FS = 0.0 ]s&    [ score:FT = 0.0 ] [ score:MS = 0.0 ]s    [ score:MT = 0.0 ]
(   R(   t	   TypeErrorR*   (   R
   (    (    s   voiceid_ilp/sr.pyt   get_seg_header¬•   s    	c         C   s   |  j  S(   s   Return segments in Cluster(   R)   (   R
   (    (    s   voiceid_ilp/sr.pyt   get_segments¬≠   s    c         C   s.   x' |  j  D] } | j ∆í  | k r
 | Sq
 Wd S(   s   Return segment by start_timeN(   R)   R   R#   (   R
   t
   start_timet   seg(    (    s   voiceid_ilp/sr.pyt   get_segment¬±   s    c         C   s>   x7 |  j  D], } | j ∆í  | k r
 |  j  j | ∆í t Sq
 Wt S(   s   Remove segment by start_time(   R)   R   t   removeR,   t   False(   R
   R:   R;   (    (    s   voiceid_ilp/sr.pyt   remove_segment¬∏   s
    c         C   sR   t  | ∆í } | |  j k r+ | |  j | <n# |  j | | k  rN | |  j | <n  d S(   sP  Add a speaker with a computed score for the cluster, if a better
        score is already present the new score will be ignored.

        :type identifier: string
        :param identifier: the speaker identifier

        :type score: float
        :param score: score computed between the cluster
                wave and speaker modelN(   t   floatR+   (   R
   R   t   scoret   val(    (    s   voiceid_ilp/sr.pyt   add_speaker√Ä   s
    
c         C   s(   |  j  d k r! |  j ∆í  |  _  n  |  j  S(   sO   Set the right speaker for the cluster if not set and returns
         its name.N(   R   R#   t   get_best_speaker(   R
   (    (    s   voiceid_ilp/sr.pyR   √ë   s    c         C   s   t  |  _ | |  _ d S(   s‚Ä∞   Set the cluster speaker identifier 'by hand'.

        :type identifier: string
        :param identifier: the speaker name or identifierN(   R>   R-   R   (   R
   R   (    (    s   voiceid_ilp/sr.pyt   set_speaker√ò   s    	c         C   s=   y$ t  |  j j ∆í  ∆í t |  j ∆í SWn t k
 r8 d SXd S(   sS   Get the mean of all the scores of all the tested speakers for
         the cluster.g        N(   t   sumR+   t   valuest   lent   ZeroDivisionError(   R
   (    (    s   voiceid_ilp/sr.pyt   get_mean√†   s    $
c         C   s   |  j  S(   s9   Get the cluster name assigned by the diarization process.(   R(   (   R
   (    (    s   voiceid_ilp/sr.pyt   get_name√®   s    c         C   s  d } y t  |  j j ∆í  ∆í |  _ Wn t k
 r> d |  _ n Xd } |  j ∆í  } t |  j j ∆í  ∆í d k r{ |  j ∆í  } n d } d } | d k r¬† | | } n | } |  j | k r√∏ | d k r√∏ x4 |  j D]& } |  j | |  j k r√ã | } Pq√ã q√ã Wn  | d	 k r
d } n  | S(
   s7  Get the best speaker for the cluster according to the scores.
         If the speaker'spk score is lower than a fixed threshold or is too
         close to the second best matching voice,
         then it is set as "unknown".

         :rtype: string
         :returns: the best speaker matching the cluster wavg     ‚Ç¨@√Äi≈ì√ø√ø√øt   unknowni   g      √†?i    i√ø√ø√ø√øg\¬è√Ç√µ(\√ü?g√¨Q¬∏‚Ä¶√´¬±?(   t   maxR+   RG   R0   t
   ValueErrort   get_distanceRH   t   get_m_distance(   R
   t   max_valR   t   distancet
   mean_distancet   threst   spk(    (    s   voiceid_ilp/sr.pyRD   √¨   s,    


	c         C   s&   t  |  j j ∆í  d d ‚Äû  d t ∆íd  S(   s√®   Get the best five speakers in the db for the cluster.

        :rtype: array of tuple
        :returns: an array of five most probable speakers represented by
            ordered tuples of the form (speaker, score) ordered by score.t   keyc         S   s   |  \ } } | | f S(   N(    (   t   .0RV   RB   (    (    s   voiceid_ilp/sr.pyt   <lambda>  s    t   reversei   (   t   sortedR+   t	   iteritemsR,   (   R
   (    (    s   voiceid_ilp/sr.pyt
   get_best_five  s    	c         C   s≈∏   i d d 6d d 6d d 6} t  } xK |  j D]@ } | j ∆í  } | |  j k r+ t } | | c | j ∆í  7<q+ q+ W| r‚Äù | d | d k r¬ç d Sd Sn |  j Sd S(   si   Get the computed gender of the Cluster.

        :rtype: char
        :returns: the gender of the clusteri    t   Mt   Ft   UN(   R>   R)   R   R%   R,   R   (   R
   t   gent   differR;   t   ggg(    (    s   voiceid_ilp/sr.pyR     s    c         C   s^   |  j  j ∆í  } | j d t ∆í y  t | d ∆í t | d ∆í SWn t t f k
 rY d SXd S(   sV   Get the distance between the best speaker score and the closest
        speaker score.RY   i   i    i√ø√ø√ø√øN(   R+   RG   t   sortR,   t   abst
   IndexErrorRN   (   R
   RG   (    (    s   voiceid_ilp/sr.pyRO   3  s     c         C   s   g  } g  } x8 |  j  D]- } | j | ∆í | j t |  j  | ∆í ∆í q Wd G| GHd G| GH| j t | ∆í ∆í } | | GH| | S(   sm    Gives the voice in the db which has least distance from the cluster
        wav as the best matched speaker s
   Speaker arrays   Value array(   R+   R4   Rd   t   indext   min(   R
   t   SpeakRt   ValUet   speakert   ind(    (    s   voiceid_ilp/sr.pyt   _get_matched_speaker=  s    
			c         C   s5   t  |  j j ∆í  ∆í } t t | ∆í t |  j ∆í  ∆í ∆í S(   sa   Get the distance between the best speaker score and the mean of
        all the speakers' scores.(   RM   R+   RG   Rd   RJ   (   R
   R0   (    (    s   voiceid_ilp/sr.pyRP   Q  s    c         C   s   |  j  | |  j d  ∆í d S(   s   Generate a segmentation file for the cluster.

        :type filename: string
        :param filename: the name of the seg filei√º√ø√ø√øN(   t   _generate_a_seg_fileR.   (   R
   t   filename(    (    s   voiceid_ilp/sr.pyt   generate_seg_fileW  s    c         C   s‚Ä∞   t  | d ∆í } | j |  j ∆í  ∆í |  j d j |  j ∆í  ∆í } | | d <d | d <|  j d | d <| j d t | ∆í ∆í | j ∆í  d S(   sA  Generate a segmentation file for the given showname.

        :type filename: string
        :param filename: the name of the seg file

        :type first_col_name: string
        :param first_col_name: the name in the first column of the seg file,
               in fact the name and path of the corresponding wave filet   wi    i   i   i   s   %s %s %s %s %s %s %s %s
N(	   t   opent   writeR8   R)   R   RK   R&   t   tuplet   close(   R
   Rn   t   first_col_namet   f_descR   (    (    s   voiceid_ilp/sr.pyRm   ^  s    	

c         C   s$   |  j  j | j  ∆í |  j  j ∆í  d S(   sq   Merge the Cluster with another.

        :type other: Cluster
        :param other: the cluster to be merged withN(   R)   t   extendRc   (   R
   R   (    (    s   voiceid_ilp/sr.pyR   q  s    c         C   sI   |  j  j |  j | ∆í |  _  | |  _ x |  j D] } | j | ∆í q. Wd S(   s‚Ç¨   Rename the cluster and all the relative segments.

        :type label: string
        :param label: the new name of the clusterN(   R*   t   replaceR(   R)   R   (   R
   R2   R;   (    (    s   voiceid_ilp/sr.pyR   y  s    	c         C   s¬∏   |  j  } |  j ∆í  } t j j | j d ∆í d | ∆í } t j | ∆í } | j ∆í  g  | D] } t j j | | ∆í ^ qW } t j j | j d ∆í d | d ∆í |  _ t	 j
 | |  j ∆í d S(   s7   Take all the wave of a cluster and build a single wave.t   .i    s   .wavN(   R/   RK   t   ost   patht   joint   splitt   listdirRc   R.   t   fmt   merge_waves(   R
   R/   t   namet   videoclustert	   listwavest   filt   listw(    (    s   voiceid_ilp/sr.pyR‚Ç¨   ∆í  s    	"
()c         C   s¬±   |  j  } |  j ∆í  } t j j | | ∆í } y t j | ∆í } Wn t k
 rQ t SXg  | D] } t j j | | ∆í ^ qY } x0 | D]( } t j j | ∆í t	 k r¬• q¬Å q¬Å t Sq¬Å Wt	 S(   s‚Äò   Check if the wave files generated for the cluster are still
        present. In case you load a json file you shold not have those
        files.(
   R/   RK   Rz   R{   R|   R~   t   OSErrorR>   t   isfileR,   (   R
   R/   R¬Å   R‚Äö   R∆í   R‚Äû   R‚Ä¶   t   wav(    (    s   voiceid_ilp/sr.pyt   has_generated_waves≈Ω  s    	
(
c         C   s¬ù   |  j  ∆í  } g  } x‚Äû |  j D]y } | j ∆í  d } | | d <t | j ∆í  ∆í | d <t | j ∆í  ∆í | d <| j |  j ∆í  ∆í |  j | d <| j | ∆í q W| S(   s)   A dictionary representation of a Cluster.i   i√ø√ø√ø√øi    i   i   (	   R   R)   R   R   R   R   R4   RK   R+   (   R
   Rj   t   segsR;   t   tmp(    (    s   voiceid_ilp/sr.pyt   to_dict¬°  s    

c         C   s¬†   g  } g  } x] |  j  D]R } | j t j t | j ∆í  ∆í d ∆í ∆í | j t j t | j ∆í  ∆í d ∆í ∆í q Wt | ∆í j d ∆í d j d ∆í d d d !| | f S(   s   Print cluster timing.id   t    i√ø√ø√ø√øt   ]i    i   (	   R)   R4   t   utilst
   humanize_timeR@   R   R   R   R}   (   R
   t	   start_segt   end_segR;   (    (    s   voiceid_ilp/sr.pyt   print_segments¬Ø  s    &*c         C   sm   t  |  j ∆í  ∆í } xT |  j D]I } | j ∆í  } | rD |  j | d <n
 |  j | d <| d t | ∆í 7} q W| S(   s$   String representation of the segmenti√ø√ø√ø√øs   %s %s %s %s %s %s %s %s
(   R   R8   R)   R   R   R(   Rs   (   R
   t   set_speakerst   resultR;   R   (    (    s   voiceid_ilp/sr.pyt
   _get_seg_repr¬∏  s    
c         C   s.   d } x! |  j  D] } | | j ∆í  7} q W| S(   s   Return cluster duration.i    (   R)   R   (   R
   t   durR;   (    (    s   voiceid_ilp/sr.pyR   √Ñ  s    c         C   s"   t  j |  j ∆í } | |  j ∆í  f S(   N(   R   t
   wave_durationR.   R   (   R
   t   w_dur(    (    s   voiceid_ilp/sr.pyt   _verify_duration√ã  s    N("   R    R!   R"   R#   R   R3   R6   R8   R9   R<   R?   RC   R   RE   RJ   RK   RD   R\   R   RO   Rl   RP   Ro   Rm   R   R   R‚Ç¨   R‚Ä∞   R≈í   R‚Äú   R,   R‚Äì   R   R≈°   (    (    (    s   voiceid_ilp/sr.pyR$   l   s<   												)	
		
						
						t   Voiceidc           B   s√ô  e  Z d  Z e d ‚Äû  ∆í Z e d ‚Äû  ∆í Z d ‚Äû  Z d ‚Äû  Z d ‚Äû  Z d ‚Äû  Z	 d ‚Äû  Z
 d ‚Äû  Z d	 ‚Äû  Z d
 ‚Äû  Z
 d ‚Äû  Z d ‚Äû  Z d
 ‚Äû  Z d ‚Äû  Z d ‚Äû  Z d ‚Äû  Z d ‚Äû  Z d ‚Äû  Z d ‚Äû  Z d ‚Äû  Z d ‚Äû  Z d ‚Äû  Z d ‚Äû  Z d ‚Äû  Z d ‚Äû  Z d ‚Äû  Z d ‚Äû  Z e d ‚Äû Z  d ‚Äû  Z! d ‚Äû  Z" d ‚Äû  Z# e$ e$ d  ‚Äû Z% d! ‚Äû  Z& d" ‚Äû  Z' d# ‚Äû  Z( d$ ‚Äû  Z) e$ e$ d% d& ‚Äû Z* d1 e$ e$ d% d' d( ‚Äû Z, d) ‚Äû  Z- d* ‚Äû  Z. d+ e$ d, ‚Äû Z/ d- ‚Äû  Z0 d. ‚Äû  Z1 d1 d/ ‚Äû Z2 d0 ‚Äû  Z3 RS(2   s‚Ä∞  The main object that represents the file audio/video to manage.

    :type db: object
    :param db: the VoiceDB database instance

    :type filename: string
    :param filename: the wave or video file to be processed

    :type single: boolean
    :param single: set to True to force to avoid diarization (a faster
           approach) only in case you have just a single speaker in the filec         C   s;   t  | d ∆í } t | j ∆í  ∆í } | j ∆í  t j |  | ∆í S(   s√ì   Build a Voiceid object from json file.

        :type json_filename: string
        :param json_filename: the file containing a json style python
                dictionary representing a Voiceid object instancet   r(   Rq   t   evalt   readRt   R‚Ä∫   t	   from_dict(   t   vdbt
   json_filenamet   opft   jdict(    (    s   voiceid_ilp/sr.pyt   from_json_file√ù  s    
c         C   sY  t  |  | d ∆í } t j j | d ∆í d } yx| d D]√µ } | j | d ∆í } | s¬Å t | d | d d | | d ∆í } n  t | d t | d d	 ∆í t d	 | d
 | d ∆í | d d d | d g ∆í } | j | ∆í | d | _	 y | j	 | d | _
 Wn t k
 rd
 GHn X| j | d | ∆í q; WWn t
 k
 rTt d ∆í ‚Äö n X| S(   s¬ø   Build a Voiceid object from json dictionary.

        :type json_dict: dictionary
        :param json_dict: the json style python dictionary representing a
            Voiceid object instancet   urli    t
   selectionst   speakerLabelRj   R%   i   t	   startTimeid   t   endTimeR_   R+   s/   ERROR: For unknown speaker there is not a scores/   ERROR: Failed load dict, maybe in wrong format!(   R‚Ä∫   Rz   R{   t   splitextt   get_clusterR$   R   R   R6   R+   R0   t   KeyErrort   add_update_clusterRN   t	   Exception(   R¬†   t	   json_dictt   vidR/   t   elmt   cluR;   (    (    s   voiceid_ilp/sr.pyR≈∏   √©  s*    


	
c         C   s√é   i d d 6d d 6d d 6d d 6d	 d
 6|  _  i d d 6d d 6d
 d 6d d 6d d
 6|  _ i  |  _ i  |  _ d |  _ d |  _ t |  _ | |  _ t	 j
 | ∆í d |  _ |  _
 |  j | ∆í d |  _ d |  _ d S(   s`  
        :type vdb: object
        :param vdb: the VoiceDB database instance

        :type filename: string
        :param filename: the wave or video file to be processed

        :type single: boolean
        :param single: set to True to force to avoid diarization (a faster
        approach) only in case you have just a single speaker in the filet   file_loadedi    t   file_convertedi   t   diarization_donei   t	   trim_donei   s   speakers matchedi   t   converting_filet   diarizationt   trimmings   voice matchings   extraction finishedt    iK   N(   i   iK   (   t
   status_mapt   working_mapt	   _clusterst   _matchedt   _extt   _timeR>   t   _interactivet   _dbR¬è   t   ensure_file_existsR#   t	   _filenameR   t
   _set_filenamet   _statust
   _diar_conf(   R
   R¬†   Rn   (    (    s   voiceid_ilp/sr.pyR     s     
						

	c         C   s   |  j  j | ∆í S(   N(   R¬Ω   t   __getitem__(   R
   RV   (    (    s   voiceid_ilp/sr.pyR√à   #  s    c         C   s
   |  j  j ∆í  S(   s+   Just iterate over the cluster's dictionary.(   R¬Ω   t   __iter__(   R
   (    (    s   voiceid_ilp/sr.pyR√â   &  s    c         C   s   |  j  S(   s¬Ω   Get the status of the computation.
            0:'file_loaded',
            1:'file_converted',
            2:'diarization_done',
            3:'trim_done',
            4:'speakers matched'(   R√Ü   (   R
   (    (    s   voiceid_ilp/sr.pyt
   get_status*  s    c         C   s   |  j  |  j ∆í  S(   s√ó   
        Get a string representation of the working status.
            0:'converting_file',
            1:'diarization',
            2:'trimming',
            3:'voice matching',
            4:'extraction finished'(   R¬º   R√ä   (   R
   (    (    s   voiceid_ilp/sr.pyt   get_working_status3  s    	c         C   s   |  j  S(   s   Get the VoiceDB instance used.(   R√Ç   (   R
   (    (    s   voiceid_ilp/sr.pyt   get_db>  s    c         C   s   |  j  S(   N(   R√Å   (   R
   (    (    s   voiceid_ilp/sr.pyt   _get_interactiveC  s    c         C   s
   | |  _  d  S(   N(   R√Å   (   R
   R0   (    (    s   voiceid_ilp/sr.pyt   _set_interactiveF  s    c         C   s   |  j  S(   s2   Get the clusters recognized in the processed file.(   R¬Ω   (   R
   (    (    s   voiceid_ilp/sr.pyt   get_clustersI  s    c         C   s
   | |  _  d  S(   N(   R¬Ω   (   R
   R0   (    (    s   voiceid_ilp/sr.pyt
   _set_clustersM  s    c         C   s   |  j  S(   N(   R√Ä   (   R
   (    (    s   voiceid_ilp/sr.pyt	   _get_timeP  s    c         C   s
   | |  _  d  S(   N(   R√Ä   (   R
   R0   (    (    s   voiceid_ilp/sr.pyt	   _set_timeS  s    c         C   s√ø   d j  | j ∆í  ∆í } d } t j j } xB | D]: } | j ∆í  s[ | d d d | d g k r. | | 7} q. q. Wy t j | | ∆í WnA t j k
 r√É } d | | f } t	 | ∆í | k r¬∫ q√Ñ | ‚Äö n Xt
 j | ∆í | |  _ t j j
 |  j ∆í \ |  _ |  _ d S(   s,   Set the filename of the current working filet   _R¬∫   Ry   t   :t   -s   `%s` and `%s` are the same fileN(   R|   R}   Rz   R{   t   sept   isalnumt   shutilt   copyt   ErrorR   R¬è   R√É   R√Ñ   R¬™   R   R¬ø   (   R
   Rn   t   tmp_filet   new_filet   pathsept   chart   errt   msg(    (    s   voiceid_ilp/sr.pyR√Ö   V  s     
'

	c         C   s   |  j  S(   N(   R¬æ   (   R
   (    (    s   voiceid_ilp/sr.pyt   get_matched_speakerj  s    c         C   s   |  j  S(   s)   Get the name of the current working file.(   R√Ñ   (   R
   (    (    s   voiceid_ilp/sr.pyt   get_filenamem  s    c         C   s   |  j  S(   s-   Get the basename of the current working file.(   R   (   R
   (    (    s   voiceid_ilp/sr.pyt   get_file_basenameq  s    c         C   s   |  j  S(   s.   Get the extension of the current working file.(   R¬ø   (   R
   (    (    s   voiceid_ilp/sr.pyt   get_file_extensionu  s    c         C   s(   y |  j  | SWn t k
 r# d SXd S(   s   Get a the cluster by a given label.

        :type label: string
        :param label: the cluster label (i.e. S0, S12, S44...)N(   R¬Ω   R¬¨   R#   (   R
   R2   (    (    s   voiceid_ilp/sr.pyR¬´   y  s    
c         C   s   | |  j  | <d S(   s√ê   Add a cluster or update an existing cluster.

        :type label: string
        :param label: the cluster label (i.e. S0, S12, S44...)

        :type cluster: object
        :param cluster: a Cluster objectN(   R¬Ω   (   R
   R2   R   (    (    s   voiceid_ilp/sr.pyR¬≠   ∆í  s    c         C   s   |  j  | =d S(   sx   Remove and delete a cluster.

        :type label: string
        :param label: the cluster label (i.e. S0, S12, S44...)N(   R¬Ω   (   R
   R2   (    (    s   voiceid_ilp/sr.pyt   remove_cluster¬ç  s    c         C   s9   g  } x, |  j  D]! } | j |  j  | j ∆í  ∆í q W| S(   s≈∏   Return the time slices with all the information about start time,
        duration, speaker name or "unknown", gender and sound quality
        (studio/phone).(   R¬Ω   Rw   R≈í   (   R
   t   totR¬≤   (    (    s   voiceid_ilp/sr.pyt   get_time_slices‚Äù  s    c         C   s5   d } x( |  j  D] } | |  j  | j ∆í  7} q W| S(   s7   Return the duration of all the time slices in the audioi    (   R¬Ω   R   (   R
   R‚Äî   R¬≤   (    (    s   voiceid_ilp/sr.pyR   ≈æ  s    c         C   s/   x( |  j  D] } | GH|  j  | j ∆í  GHq
 Wd  S(   N(   R¬Ω   R≈°   (   R
   R¬≤   (    (    s   voiceid_ilp/sr.pyR≈°   ¬•  s    c         C   s/   i  } x" |  D] } |  | j  ∆í  | | <q
 W| S(   s8   A dictionary map between speaker label and speaker name.(   R   (   R
   R+   R¬≤   (    (    s   voiceid_ilp/sr.pyt   get_speakers_map¬´  s    
c         C   sM   d |  _  t j |  j ∆í  ∆í } | |  j ∆í  k r@ |  j | ∆í n  d |  _  d S(   s]   In case the input file is a video or the wave is in a wrong format,
         convert to wave.i    i   N(   R√Ü   R   t   file2wavR√¢   R√Ö   (   R
   t   fname(    (    s   voiceid_ilp/sr.pyt   _to_wav¬≤  s
    	c         C   sh   d } x+ |  j  D]  } | |  j  | j | ∆í 7} q Wt |  j ∆í  d d ∆í } | j | ∆í | j ∆í  d S(   s]   Generate a seg file according to the information acquired about the
        speech clusteringR¬∫   s
   .ev_is.segRp   N(   R¬Ω   R‚Äì   Rq   R√£   Rr   Rt   (   R
   R‚Äù   R‚Ä¢   R¬≤   t   f_seg(    (    s   voiceid_ilp/sr.pyRo   ¬ª  s    
c         C   sF   d |  _  t j |  j t |  j d ∆í t |  j d ∆í ∆í d |  _  d S(   s¬¢   Run the diarization process. In case of single mode (single speaker
        in the input file) just create the seg file with silence and gender
        detection.i   i    i   N(   R√Ü   R   R¬∏   R   R   R√á   (   R
   (    (    s   voiceid_ilp/sr.pyR¬∏   √Ö  s    	c         C   s&   d |  _  t j |  j ∆í d |  _  d S(   sf   Trim the wave input file according to the segmentation in the seg
        file. Run after diarization.i   i   N(   R√Ü   R   t   seg2trimR   (   R
   (    (    s   voiceid_ilp/sr.pyt   _to_trim√é  s    	c         C   s   t  |  j d |  j ∆í d  S(   Ns
   .ev_is.seg(   t   extract_clustersR   R¬Ω   (   R
   (    (    s   voiceid_ilp/sr.pyt   _extract_clusters√ï  s    c         C   s√ê  |  j  ∆í  } xC |  j D]8 } |  | j ∆í  |  | j t j j | | d ∆í ∆í q Wi  } x; |  j D]0 } t j j | | ∆í d } |  | j | | <qb W|  j ∆í  j	 | ∆í } d ‚Äû  } xK | D]C }	 | |	 ∆í } x. | |	 D]" }
 |  | j
 |
 | |	 |
 ∆í q√ò Wq¬ª W| sd GHn  i  } x¬≥ |  j D]¬® } | sT| rTd GHd G| GH|  | j ∆í  qTn  |  | j ∆í  | | <|  | j
 | | ∆í | t k r |  j t ∆í t | | | | ∆í | | <}
 |  | j
 |
 ∆í q q Wd S(   s   Match for voices in the dbs
   .ev_is.segs   .wavc         S   s$   |  j  t j j ∆í d j  d ∆í d S(   Ni√ø√ø√ø√øRy   i    (   R}   Rz   R{   R√ñ   (   RÀÜ   (    (    s   voiceid_ilp/sr.pyt   wav_to_cluster√¶  s    R¬∫   s"   **********************************s   speaker N(   R√£   R¬Ω   R‚Ç¨   Ro   Rz   R{   R|   R%   R√å   t
   voices_lookupRC   R‚Äú   RD   RE   R,   R√é   t   _interactive_training(   R
   t   interactivet   quiett   basenameR   t	   wav_filest   filebasenameR‚Ä¢   R√±   RU   R≈ì   R+   R¬≤   t   best(    (    s   voiceid_ilp/sr.pyt   _match_clusters√ò  s>    	
$		
c         C   s≈Ω   g  } |  j  j ∆í  } x' | D] } | j |  j  j | ∆í ∆í q Wd } xB | D]: } d t | ∆í } | j | ∆í | |  j  | <| d 7} qL Wd S(   s!   Rename all clusters from S0 to Sni    t   Si   N(   R¬Ω   R√ô   R4   t   popR   R   (   R
   t   all_clusterst
   temp_clustersR¬≤   t   idxR2   (    (    s   voiceid_ilp/sr.pyt   _rename_clusters  s    



c         C   se   d } d } | | k  r' | } | } n | } | } |  j  | ∆í } |  j j | ∆í } | j | ∆í d S(   s'   Merge two clusers and delete the secondR¬∫   N(   R¬´   R¬Ω   R√º   R   (   R
   t   cl1t   cl2R2   t	   to_deletet   to_keept	   to_remove(    (    s   voiceid_ilp/sr.pyt   _merge_clusters  s    	c         C   s;  |  j  j ∆í  } g  } xB | D]: } | | j ∆í  } x! | D] } | j | | f ∆í q9 Wq W| j ∆í  g  } | j i  ∆í d } d  } x| D]√º } | }	 | r| d }
 |	 d } |	 d } |
 | k rL| | | k rg  | | | <| | | j | | d g ∆í q|y | | | j | ∆í Wq|t k
 rH| | | j | ∆í q|Xqt	 | | ∆í d k r| d 7} | j i  ∆í qn  |	 } q≈† Wx¬™ | D]¬¢ }
 x‚Ñ¢ |
 D]‚Äò } |
 | j d t
 ∆í d  } xn |
 | D]b } | j ∆í  } |  j | ∆í j
 | ∆í } | r%| j | ∆í |  j | ∆í j | j ∆í  ∆í n  | } q√âWq≈æWq‚ÄòWd  S(   Ni    i   RY   (   R¬Ω   R√ô   R9   R4   Rc   R#   Rw   Rf   RN   RH   R,   R   R¬´   R<   R   R?   (   R
   t   clusterst   all_segsR¬≤   t   c_segsR;   t   to_mergeR√ø   t   prevt   currentt	   p_clusterR   R5   t	   groupdictt   cluster_keyt   current_segt	   seg_start(    (    s   voiceid_ilp/sr.pyt   _automerge_segments!  sT    







"



	
c      	   C   s  |  j  ∆í  j ∆í  } t } x¬¶ | D]≈æ } | | } x‚Äπ | D]∆í } | | } | | k r6 | j ∆í  d k r6 | j ∆í  | j ∆í  k r6 |  j j | ∆í r6 |  j j | ∆í r6 t } |  j | | ∆í q6 q6 Wq W| r|  j ∆í  t	 j
 |  j ∆í  ∆í |  j d t ∆í |  j
 ∆í  n  d S(   s@   Check for Clusters representing the same speaker and merge them.RL   R‚Äù   N(   R√è   R√ô   R>   R   R¬Ω   t   has_keyR,   R  R   R√ò   t   rmtreeR√£   Ro   R√Æ   (   R
   R√Ω   t   changedt   cl_1t   c_c1t   cl_2t   c_c2(    (    s   voiceid_ilp/sr.pyt   automerge_clusterse  s    



Z
i   c         C   s√°   | d k  r d } n  |  j  ∆í  j | ∆í d |  _ t j ∆í  } | sQ |  j ∆í  GHn  |  j ∆í  | so |  j ∆í  GHn  |  j ∆í  t j ∆í  | } | s¬ù |  j ∆í  GHn  |  j ∆í  d |  _ | s√Ñ |  j ∆í  GHn  |  j | | | | | ∆í d S(   sX  Identify the speakers in the audio wav according to a speakers
        database. If a speaker doesn't match any speaker in the database then
        sets it as unknown. In interactive mode it asks the user to set
        speakers' names.

        :type interactive: boolean
        :param interactive: if True the user must interact to give feedback or
                train the computed clusters voices

        :type quiet: boolean
        :param quiet: silent mode, no prints in batch mode

        :type thrd_n: integer
        :param thrd_n: max number of concurrent threads for voice db matchesi   i    i   N(	   R√å   t   set_maxthreadsR√Ü   t   timeR√ã   R√´   R¬∏   R√Æ   t   _cluster_matching(   R
   R√¥   R√µ   t   thrd_nR:   t   diarization_time(    (    s   voiceid_ilp/sr.pyt   extract_speakers~  s(    		


	i    c      	   C   s‚Ç¨  |  j  ∆í  } |  j ∆í  |  j | | ∆í d |  _ t j | d ∆í } t j ∆í  | } |  j | ∆í | ss |  j ∆í  GHn  | r‚Äù d GH|  j	 | d t
 ∆ín  | s|| s|d GH|  j GHx√≥ |  j D]√® }	 d GHd G|	 GHx/ |  |	 j D]  }
 d |
 |  |	 j |
 f GHq√ô Wd	 GH|  |	 j
 ∆í  } y$ |  |	 j ∆í  } |  |	 j ∆í  }
 Wn# t t f k
 r[d
 } d
 }
 n Xd |  |	 | | |
 f GHd |  |	 j ∆í  GH|  |	 j ∆í  |  j |	 <q¬∑ W|  j ∆í  j ∆í  } t | d
 ∆í t | d ∆í t | d ∆í } | d k rLt | | ∆í } | t | ∆í } d t j | ∆í | t j | ∆í | t j | ∆í | | | f GHqyd t j | ∆í | t j | ∆í | | f GHq|n  d S(   s   Match for voices in the dbi   s   .wavs   Updating dbt	   automerges   self._clusterss"   **********************************s   speaker s   	 %s %ss   	 ------------------------i    sM   	 best speaker: %s (distance from 2nd %f - mean %f - distance from mean %f ) s   Best matched speaker: %sR^   R]   R_   sp   
wav duration: %s
all done in %dsec (%s) (diarization %dsec time:%s )  with %s threads and %d voices in db (%f) sY   
wav duration: %s
match clusters done in %dsec (%s)  with %s threads and %d voices in db N(   R√£   R√∞   R√∫   R√Ü   R   RÀú   R  R√í   R√ã   t	   update_dbR,   R¬Ω   R+   RO   RJ   RP   R¬¨   RN   Rl   R¬æ   R√å   t   get_speakersRH   R#   R@   R¬è   R¬ê   (   R
   R  R√¥   R√µ   R  t   start_tR√∂   t   sect
   total_timeR¬≤   Rj   RR   t   meant
   m_distancet   speakers_in_dbt
   tot_voicest
   voice_timet   t_f_s(    (    s   voiceid_ilp/sr.pyR  ¬©  sf    
	
	

,c         C   sH   |  j  ∆í  j | | | ∆í } x& | D] } |  | j | | | ∆í q" Wd S(   s9   A wrapper to match the voices each in a different Thread.N(   R√å   t   match_voiceRC   (   R
   R   t   wav_namet   db_entryR%   t   resultst   res(    (    s   voiceid_ilp/sr.pyt   _match_voice_wrapper√¨  s    
c         C   s%   | d k r d |  _  n	 d |  _  d S(	   s1   Set a diarization configuration for noisy videos i    i   g      √∏?i   gffffff√∂?N(   i   g      √∏?(   i   gffffff√∂?(   R√á   (   R
   t   mode(    (    s   voiceid_ilp/sr.pyt   set_noise_mode√≤  s    i   c            s¬≤  d ‚Äû  ‚Ä∞  ‚Ä°  ‚Ä° ‚Ä° f d ‚Ä†  } i  } t  j j |  j ∆í  d ∆í sS |  j d t ∆í n  x|  j j ∆í  D]‚Ä∞ ÀÜ j t k rc ÀÜ j	 ∆í  } ÀÜ j
 ∆í  ‚Ä∞ ÀÜ d k rE| d k rEy~ | ÀÜ j k r%ÀÜ j | } x[ ÀÜ j D]M } | | k r√ë ÀÜ j | } t t | ∆í t | ∆í ∆í d k  r| ‚Ä∞ qq√ë q√ë Wn  WqEd t
 ÀÜ j ∆í GHqEXn  |  j ∆í  }	 ÀÜ  | |	 ∆í }
 |
 d } ÀÜ j ∆í  s¬ç|  j ∆í  |  j ∆í  n  ÀÜ j ∆í  y$ t j ÀÜ j | ∆í t j | ∆í Wn t k
 r√ìd	 GHn Xy t j |
 d ∆í Wn% t k
 rÀÜ j |
 d |
 ∆í n XÀÜ j ∆í  } t j d
 | d |  |
 | |	 | ÀÜ f ∆í | | <| | j ∆í  t ÀÜ _ qc qc Wx/ | D]' }
 | |
 j ∆í  rp| |
 j  ∆í  qpqpW| r¬Æ|  j! ∆í  n  d S(
   s%  Update voice db after some changes, for example after a train
        session.

        :type t_num: integer
        :param t_num: number of contemporary threads processing the update_db

        :type automerge: boolean
        :param automerge: true to do the automerge or false to not do itc         S   s√â   d } t  j j | |  ∆í }  |  d } t  j j | ∆í r x` t r{ |  d t | ∆í d } t  j j | ∆í sn Pn  | d } q: Wn t |  d d ∆í j ∆í  |  St |  t | ∆í d d ∆í j ∆í  |  t | ∆í S(   s    Find a non taken wave (base)namei    s   .wavR¬∫   i   Rp   (   Rz   R{   R|   t   existsR,   R   Rq   Rt   (   R2   t   basedirt   contR.  (    (    s   voiceid_ilp/sr.pyt   _get_available_wav_basename  s    
	!c            s≈∏  y t  j | d ∆í Wn) t k
 r@ |  | j | d | ∆í n Xt  j | d ∆í |  | j } | d k r¬π |  j ∆í  j | | |  | j |  | j ∆í |  j | | d | |  | j ∆í n  |  j	 ∆í  } ÀÜ  ÀÜ | ∆í } | d }	 | | k r√®| d k r√®ÀÜ j
 ∆í  s|  j ∆í  |  j ∆í  n  ÀÜ j
 ∆í  y$ t j ÀÜ j |	 ∆í t  j |	 ∆í Wn t k
 r_d GHn Xy t  j | d ∆í Wn% t k
 r≈ìÀÜ j | d | ∆í n X|  j ∆í  j | | | |  | j ∆í }
 |
 r√®|  | j } | j | ∆í q√®n  | d k r|  | j | ∆í n  t j s‚Ä∫yn t j d | ∆í t j d | ∆í t j d | ∆í t j j |	 ∆í r~t j d |	 ∆í t j | d ∆í n  Wq‚Ä∫t k
 r‚Äîd	 GHq‚Ä∫Xn  d
 S(   s)   A procedure to wrap the model building to run in a Thread 
            :type wave_b: string
            :param wave_b: path for the wave renamed with the current speaker name
            :type cluster: string
            :param cluster: the cluster label
            :type wave_dir: string
            :param wave_dir: basename for the wave
            :type new_speaker: string
            :param new_speaker: the current speaker name
            :type old_speaker: string
            :param old_speaker: the old speaker name
            
            s
   .ev_is.segs   .wavRL   s'   WARNING: error renaming some wave filess   %s.ev_is.segs   %s.init.gmms   %s.wavs   %ss/   WARNING: error deleting some intermediate filesN(   R¬è   R√É   t   IOErrorRm   R0   R√å   t	   add_modelR%   R2  R√£   R‚Ä∞   R√´   R√Æ   R‚Ç¨   R√ò   t   moveR.   R‚Ä†   t   remove_modelR+   R√º   RE   t
   CONFIGURATIONt   KEEP_INTERMEDIATE_FILESRz   R=   R{   R5  (   R
   t   wave_bR   t   wave_dirt   new_speakert   old_speakert   old_cluster_valuet   old_basenamet
   old_b_filet   old_wav_namet   removedt   a(   R8  R¬≤   t   old_s(    s   voiceid_ilp/sr.pyt   _build_model_wrapper  s^    

	




	

 	
s
   .ev_is.segR‚Äù   RL   g√¨Q¬∏‚Ä¶√´¬±?s	   updatedb s   .wavs'   WARNING: error renaming some wave filest   targett   argsN("   Rz   R{   R5  R√£   Ro   R>   R¬Ω   RG   R-   R   RD   R+   Rd   R   R‚Ä∞   R√´   R√Æ   R‚Ç¨   R√ò   R;  R.   R¬è   R√É   R‚Ä†   R9  Rm   RK   t	   threadingt   Threadt   startR,   t   is_aliveR|   R  (   R
   t   t_numR!  RJ  t   thrdst   current_speakert	   c_s_scoret   st   s_scoreR√∂   t   b_fileR.  t
   cluster_labelt   thr(    (   R8  R¬≤   RI  s   voiceid_ilp/sr.pyR"  √π  sf    
	R 

"	




	
	
c         C   sX   d } d } x7 |  j  ∆í  D]) } | d | d | d | d f 7} q Wd } | | | S(   s√å   Return the Adobe XMP representation of the information about who is
        speaking and when. The tags used are Tracks and Markers, the ones used
        by Adobe Premiere for speech-to-text information.s√º  <?xml version="1.0"?>
<x:xmpmeta xmlns:x="adobe:ns:meta/" x:xmptk="XMP Core 4.4.0">
    <rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#">
    <rdf:Description  xmlns:xmpDM="http://ns.adobe.com/xmp/1.0/DynamicMedia/">
            <xmpDM:Tracks>
                <rdf:Bag>
                    <rdf:li>
                        <rdf:Description
                         xmpDM:trackName="Speaker identification">
                            <xmpDM:markers>
                                <rdf:Seq>R¬∫   s  
                                    <rdf:li
                                     xmpDM:startTime="%seg"
                                     xmpDM:duration="%seg"
                                     xmpDM:speaker="%seg"
                                     /> i    i   i√æ√ø√ø√øs  
                                </rdf:Seq>
                            </xmpDM:markers>
                        </rdf:Description>
                    </rdf:li>
                </rdf:Bag>
            </xmpDM:Tracks>
        </rdf:Description>
    </rdf:RDF>
</x:xmpmeta>
(   R√ß   (   R
   t   initial_tagst   inner_stringR;   t
   final_tags(    (    s   voiceid_ilp/sr.pyt
   to_xmp_string¬¨  s    )$c         C   s¬π   i |  j  ∆í  d 6|  j d 6|  j ∆í  j ∆í  d 6g  d 6} x{ |  j ∆í  D]m } | d j i t | d ∆í d d 6t | d ∆í d d	 6| d
 d 6| d d
 6| d d 6| d d 6∆í qD W| S(   s<   Return a JSON representation for the clustering information.t   durationR¬•   t   dbR¬¶   i    g      Y@R¬®   i   R¬©   i√æ√ø√ø√øRj   i√ø√ø√ø√øR¬ß   i   R%   i   R+   (   R   R√Ñ   R√å   t   get_pathR√ß   R4   R@   (   R
   t   dicR;   (    (    s   voiceid_ilp/sr.pyR≈í   √≠  s    (


c         C   sk   | s |  j  ∆í  } n  d } |  j r- d } n  t |  j ∆í  | d d ∆í } | j t | ∆í ∆í | j ∆í  d S(   sA   Write to file the json dictionary representation of the Clusters.R¬∫   s   .interactives   .jsonRp   N(   R≈í   R√Å   Rq   R√£   Rr   R   Rt   (   R
   t
   dictionaryt   prefixt	   file_json(    (    s   voiceid_ilp/sr.pyt
   write_json$  s    		c         C   s¬∏   | d k rP |  j  ∆í  y t j |  j ∆í  d ∆í Wn d GHn X|  j  t ∆í n  | d k ri |  j ∆í  n  | d k r¬¥ t |  j ∆í  d d ∆í } | j t |  j	 ∆í  ∆í ∆í | j
 ∆í  n  d S(	   s¬ø   Write to file (basename.extension, for example: myfile.srt) the
        output of the recognition process.

        :type mode: string
        :param mode: the output format: srt, json or xmpt   srts
   .ev_is.segs   File seg do not exist!t   jsont   xmps   .xmpRp   N(   Ro   R   t   seg2srtR√£   R>   Re  Rq   Rr   R   R]  Rt   (   R
   R3  t   file_xmp(    (    s   voiceid_ilp/sr.pyt   write_output/  s    
	
N(4   R    R!   R"   t   staticmethodR¬§   R≈∏   R   R√à   R√â   R√ä   R√ã   R√å   R√ç   R√é   R√è   R√ê   R√ë   R√í   R√Ö   R√°   R√¢   R√£   R√§   R¬´   R¬≠   R√•   R√ß   R   R≈°   R√®   R√´   R,   Ro   R¬∏   R√Æ   R√∞   R>   R√∫   R   R  R  R  R   R#   R  R2  R4  R"  R]  R≈í   Re  Rk  (    (    (    s   voiceid_ilp/sr.pyR‚Ä∫   √ê  s^   																			
	
		
					
				.	
		D	+B		¬≥	A	7c         C   s¬ç  d G|  GHd G| GHd G| GHt  d |  | f d ∆í } x%| D]} | j d ∆í r; d G| GH| j d ∆í d	 j d
 ∆í } d G| GHy | \ } } Wn | d } n X| j d
 | ∆í t d
 | d ∆í } | j d | ∆í d }	 | | |	 !}
 d G| GHd G|
 GH| | k r,d GHt | d d d | ∆í | | <n  | | j | d
 | j d ∆í d |
 ∆í q; q; W| j ∆í  t j	 s‚Ä∞t
 j d |  | f ∆í n  d S(   s≈†   Take all the files created by the call of wav_vs_gmm() on the whole
    speakers db and put all the results in a bidimensional dictionary.Rn   t   gmmR  s   %s.ident.%s.ev_is.segR≈ì   s   ;;R   R¬ç   i   R√ì   t
   splitted_linei    s   score:s    = R≈Ω   i   Rj   R0   t   HERER_   t   0R¬∫   Ry   i√æ√ø√ø√øN(   Rq   t
   startswithR}   Rf   RH   R$   RC   Rt   R=  R>  Rz   R=   (   R√∏   Rm  R  t   seg_fR   Rn  R   Rj   R√ø   t   iidxR0   (    (    s   voiceid_ilp/sr.pyt   manage_identE  s2    			
		%
		0
	c         C   s  |  GHt  |  d ∆í } d } | j ∆í  } | j ∆í  x√ô | D]√ë } | j d ∆í s7 | j ∆í  } | d } | | k r¬¨ t d d d d d d	 d
 t j j	 |  ∆í d	 d | ∆í | | <n  | | j
 j t | ∆í ∆í | | j
 t | d ∆í 7_
 | d
 | | _ | d | | _ q7 q7 Wd S(   s&   Read _clusters from segmentation file.R≈ì   s   ;;i√ø√ø√ø√øR   RL   R%   R_   R1   i    R/   R2   i   i   i   N(   Rq   R#   t	   readlinesRt   Rq  R}   R$   Rz   R{   R¬™   R)   R4   R   R&   R   R%   R'   (   t   segfilenameR  R√¨   t   last_clustert   rowsR   t
   speaker_id(    (    s   voiceid_ilp/sr.pyR√Ø   b  s(    


	
c      	   C   s∆í  d' } d' } | d k r! d } n d | d } | GHxHt r~y t d d ∆í } Wn t k
 rl d GHq7 n Xd GH| d' k r¬ù | j ∆í  d' k r¬ù | j ∆í  n  | d k r≈ìt |  d	 | ∆í } t j | ∆í } g  | D] } t j	 j
 | | ∆í ^ q√ì }	 d
 j
 |	 ∆í }
 d t |
 ∆í } t j d k rGd
 t |
 ∆í } | j
 d d ∆í } n  d | GHt j | ∆í } t j | d t j d t j d t j ∆í} t j d ∆í q7 n  | d k rft }
 x¬Ø |
 s_t d d ∆í } x‚Äû t rMt | ∆í d k r√´d } n  | j ∆í  s d GHPn  t d | d ∆í } | d( k r$| S| d) k r4Pn  | d* k r√ät }
 Pq√äq√äW|
 s¬±d% GHq¬±q¬±Wq7 n  | d k rv| Sd& GHq7 Wd' S(+   sW   A user interactive way to set the name to an unrecognized voice of a
    given cluster.RL   s+   The system has not identified this speaker!s'   The system identified this speaker as 's   '!s   
 1) Listen
 2) Set s    name
 Press enter to skip
> R¬∫   t   1t   /R¬ç   s   play t   win32s   vlc s   \s   \\s     Listening %s...t   stdint   stdoutt   stderri   t   2s   Type speaker name s$   or leave blank for unknown speaker: i    s.   No blank, dash or special chars allowed! Retrys	   Save as 's   '? [Y/n/m] t   yt   yet   yest   nt   not   nopt   nopet   mt   menus   Yes, no or menu, please!s"   Type 1, 2 or enter to skip, pleaseN(   R¬Å  R‚Äö  s   yesR¬∫   (   R‚Äû  s   nos   nops   nope(   RÀÜ  s   menu(   R#   R,   t	   raw_inputt   EOFErrort   pollt   killR   Rz   R~   R{   R|   t   syst   platformRx   t   shlexR}   t
   subprocesst   PopenR=  t   output_redirectR  t   sleepR>   RH   R√ó   (   R√∏   R   R   t   infot   prcR√û   R‚Äö   R∆í   t   fR‚Ä¶   t   wrdt   commandlineRL  R‚Ä∞  R¬Å   t   okk(    (    s   voiceid_ilp/sr.pyR√≥   z  sr    		

(		
	
		(   R"   R   R    R¬è   R   Rz   R¬ê  R√ò   R‚Äò  R≈Ω  RM  R  R=  t   objectR   R$   R‚Ä∫   Rt  R√Ø   R√≥   (    (    (    s   voiceid_ilp/sr.pyt   <module>   s(   	R√ø e√ø √ø √ø x		
